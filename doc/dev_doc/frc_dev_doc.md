# **é¡¹ç›® "EchoFlow": ä½å»¶è¿Ÿæ··åˆåŠ¨åŠ›AIè¯­éŸ³åŠ©æ‰‹å¼€å‘æ–‡æ¡£**

## 1. é¡¹ç›®ç›®æ ‡

æœ¬é¡¹ç›®æ—¨åœ¨æ„å»ºä¸€ä¸ªé«˜æ€§èƒ½ã€ä½å»¶è¿Ÿã€æ”¯æŒæ‰“æ–­çš„ä¸ªäººAIè¯­éŸ³åŠ©æ‰‹ã€‚å…¶æ ¸å¿ƒä½“éªŒå¯¹æ ‡â€œè±†åŒ…â€ç­‰ä¸šç•Œé¢†å…ˆäº§å“ï¼Œé€šè¿‡åˆ›æ–°çš„**æœ¬åœ°+äº‘ç«¯æ··åˆæ¶æ„**ï¼Œåœ¨ä¸ªäººç”µè„‘ï¼ˆæ‹¯æ•‘è€…R9000P, RTX 4060 8GBï¼‰ä¸Šå®ç°æè‡´çš„å“åº”é€Ÿåº¦å’Œäº¤äº’æµç•…åº¦ï¼ŒåŒæ—¶å°†æˆæœ¬é™è‡³æœ€ä½ã€‚

## 2. æ ¸å¿ƒæ¶æ„ (Hybrid Architecture)

æˆ‘ä»¬å°†é‡‡ç”¨â€œå„å–æ‰€é•¿â€çš„ç­–ç•¥ï¼Œå°†è®¡ç®—ä»»åŠ¡åˆ†é…ç»™æœ€é€‚åˆå®ƒçš„åœ°æ–¹ï¼š

```mermaid
graph TD
    subgraph "ç”¨æˆ·ä¾§ (Your PC)"
        A[ğŸ¤ éº¦å…‹é£] --> B{Python ä¸»ç¨‹åº};
        B --> C[æœ¬åœ°LLM: Llama-3 @ RTX 4060];
        E[ğŸ”Š æ‰¬å£°å™¨] --> F([ğŸ‘¤ ä½ ]);
    end

    subgraph "äº‘ç«¯ API"
        G[ASR: Deepgram API];
        H[TTS: ElevenLabs API];
    end

    B -- WebSocket éŸ³é¢‘æµ --> G;
    G -- JSON æ–‡æœ¬æµ --> B;
    C -- æœ¬åœ°æ–‡æœ¬Tokenæµ --> B;
    B -- WebSocket æ–‡æœ¬æµ --> H;
    H -- éŸ³é¢‘æµ --> D{éŸ³é¢‘æ’­æ”¾å™¨};
    D --> E;

    style A fill:#9f9,stroke:#333,stroke-width:2px
    style F fill:#9f9,stroke:#333,stroke-width:2px
    style C fill:#f9f,stroke:#333,stroke-width:2px
    style G fill:#9cf,stroke:#333,stroke-width:2px
    style H fill:#9cf,stroke:#333,stroke-width:2px
```

**æ•°æ®æµè§£æ:**
1.  **ASR (äº‘ç«¯)**: ä½ çš„è¯­éŸ³é€šè¿‡WebSocketå®æ—¶æµå‘Deepgramï¼Œåè€…å°†è¯†åˆ«å‡ºçš„æ–‡å­—æµå®æ—¶è¿”å›ã€‚
2.  **LLM (æœ¬åœ°)**: ç¨‹åºæ¥æ”¶åˆ°ASRçš„æ–‡å­—åï¼Œç«‹åˆ»é€å…¥åœ¨ä½ RTX 4060ä¸Šè¿è¡Œçš„æœ¬åœ°å¤§æ¨¡å‹ã€‚æ¨¡å‹ä»¥Tokenæµçš„å½¢å¼é«˜é€Ÿç”Ÿæˆå›åº”ã€‚
3.  **TTS (äº‘ç«¯)**: æœ¬åœ°LLMç”Ÿæˆçš„æ¯ä¸€ä¸ªæ–‡å­—Tokenï¼Œéƒ½ç«‹åˆ»é€šè¿‡WebSocketæµå‘ElevenLabsï¼Œåè€…åˆæˆå¯¹åº”çš„éŸ³é¢‘æµå¹¶è¿”å›æ’­æ”¾ã€‚

## 3. æŠ€æœ¯æ ˆ (Tech Stack)

*   **ç¼–ç¨‹è¯­è¨€**: Python 3.10+
*   **æ ¸å¿ƒæ¡†æ¶**: `asyncio` (ç”¨äºå¤„ç†å¹¶å‘çš„I/Oå¯†é›†å‹ä»»åŠ¡)
*   **æœ¬åœ°LLM**: `llama-cpp-python` (åˆ©ç”¨CUDAåœ¨NVIDIA GPUä¸Šè¿è¡ŒGGUFæ¨¡å‹)
*   **è¯­éŸ³è¯†åˆ« (ASR)**: `deepgram-sdk`
*   **è¯­éŸ³åˆæˆ (TTS)**: `elevenlabs`
*   **éŸ³é¢‘å¤„ç†**: `sounddevice` / `pyaudio` (ç”¨äºæ•è·éº¦å…‹é£è¾“å…¥)
*   **ç¯å¢ƒç®¡ç†**: `python-dotenv` (ç”¨äºç®¡ç†APIå¯†é’¥)

## 4. Phase 1: ç¯å¢ƒé…ç½® (Environment Setup)

> **æ“ä½œç³»ç»Ÿ**: Ubuntu (å·²å®‰è£…ï¼Œéå¸¸å¥½ï¼)

#### 4.1. NVIDIA é©±åŠ¨ä¸CUDA
ç¡®ä¿ä½ çš„NVIDIAé©±åŠ¨å’ŒCUDA Toolkitå·²æ­£ç¡®å®‰è£…ã€‚é€šè¿‡åœ¨ç»ˆç«¯è¿è¡Œ `nvidia-smi` æ¥éªŒè¯ã€‚ä½ åº”è¯¥èƒ½çœ‹åˆ°ä½ çš„RTX 4060çš„ä¿¡æ¯ã€‚

#### 4.2. Python è™šæ‹Ÿç¯å¢ƒ
å¼ºçƒˆå»ºè®®ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒä»¥éš”ç¦»é¡¹ç›®ä¾èµ–ã€‚

```bash
# åœ¨ä½ çš„é¡¹ç›®æ–‡ä»¶å¤¹ä¸‹
python3 -m venv venv
source venv/bin/activate
```

#### 4.3. å®‰è£…Pythonä¾èµ–
æœ€å…³é”®çš„ä¸€æ­¥æ˜¯æ­£ç¡®å®‰è£… `llama-cpp-python` ä»¥å¯ç”¨CUDAåŠ é€Ÿã€‚

```bash
# 1. å®‰è£…æ ¸å¿ƒä¾èµ–
pip install python-dotenv deepgram-sdk elevenlabs sounddevice numpy websockets aiohttp

# 2. å®‰è£…å¸¦CUDAæ”¯æŒçš„llama-cpp-python (æ­¤å‘½ä»¤ä¼šè‡ªåŠ¨ç¼–è¯‘)
# CMAKE_ARGSç¯å¢ƒå˜é‡ä¼šå‘Šè¯‰ç¼–è¯‘å™¨å¯ç”¨CUBLASæ”¯æŒ
CMAKE_ARGS="-DLLAMA_CUBLAS=on" FORCE_CMAKE=1 pip install llama-cpp-python
```

#### 4.4. ä¸‹è½½æœ¬åœ°LLMæ¨¡å‹
1.  è®¿é—® Hugging Face (hf.co)ã€‚
2.  æœç´¢ `Meta-Llama-3-8B-Instruct-GGUF`ã€‚
3.  ä»æ–‡ä»¶åˆ—è¡¨ä¸­ä¸‹è½½ä¸€ä¸ª4ä½æˆ–5ä½çš„é‡åŒ–ç‰ˆæœ¬ï¼Œä¾‹å¦‚ `Meta-Llama-3-8B-Instruct.Q4_K_M.gguf`ã€‚
4.  å°†ä¸‹è½½çš„æ¨¡å‹æ–‡ä»¶ï¼ˆçº¦4.7GBï¼‰æ”¾å…¥ä½ çš„é¡¹ç›®æ–‡ä»¶å¤¹ä¸‹çš„ `models/` ç›®å½•ä¸­ã€‚

#### 4.5. é…ç½®APIå¯†é’¥
1.  åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»ºä¸€ä¸ªåä¸º `.env` çš„æ–‡ä»¶ã€‚
2.  å‰å¾€ [Deepgram](https://deepgram.com/) å’Œ [ElevenLabs](https://elevenlabs.io/) å®˜ç½‘æ³¨å†Œå¹¶è·å–ä½ çš„API Keyã€‚
3.  å°†å¯†é’¥å†™å…¥ `.env` æ–‡ä»¶ï¼š

    ```env
    DEEPGRAM_API_KEY="your_deepgram_api_key_here"
    ELEVENLABS_API_KEY="your_elevenlabs_api_key_here"
    ```

## 5. Phase 2: ä»£ç å®ç° (Implementation)

å»ºè®®çš„é¡¹ç›®æ–‡ä»¶ç»“æ„ï¼š

```
/project_echoflow/
|-- venv/
|-- models/
|   |-- Meta-Llama-3-8B-Instruct.Q4_K_M.gguf
|-- .env
|-- config.py         # å­˜æ”¾æ‰€æœ‰é…ç½®
|-- main.py           # ä¸»ç¨‹åºï¼Œè°ƒåº¦ä¸­å¿ƒ
|-- asr_handler.py    # å¤„ç†è¯­éŸ³è¯†åˆ«
|-- llm_handler.py    # å¤„ç†æœ¬åœ°LLMæ¨ç†
|-- tts_handler.py    # å¤„ç†è¯­éŸ³åˆæˆä¸æ’­æ”¾
```

---

### `config.py`
```python
import os
from dotenv import load_dotenv

load_dotenv()

# API Keys
DEEPGRAM_API_KEY = os.getenv("DEEPGRAM_API_KEY")
ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY")

# LLM Configuration
MODEL_PATH = "models/Meta-Llama-3-8B-Instruct.Q4_K_M.gguf"
N_GPU_LAYERS = 35  # å…³é”®å‚æ•°! æ ¹æ®ä½ çš„VRAMè°ƒæ•´ï¼Œ35å¯¹8GBæ¥è¯´æ˜¯ä¸ªå¾ˆå¥½çš„èµ·ç‚¹
N_CTX = 4096       # ä¸Šä¸‹æ–‡é•¿åº¦

# Audio Configuration
MIC_SAMPLE_RATE = 16000
MIC_CHANNELS = 1
MIC_DEVICE_ID = None # `None` for default mic

# TTS Configuration
ELEVENLABS_VOICE_ID = "Rachel" # ä½ å¯ä»¥é€‰æ‹©ä»»ä½•ä½ å–œæ¬¢çš„å£°éŸ³

# Prompt
SYSTEM_PROMPT = "You are Echo, a highly responsive and friendly AI assistant. You answer concisely and clearly."
```

---

### `llm_handler.py` (æœ¬åœ°å¤§è„‘)
```python
import asyncio
from llama_cpp import Llama
import config

class LLMHandler:
    def __init__(self, from_asr_queue, to_tts_queue):
        self.from_asr_queue = from_asr_queue
        self.to_tts_queue = to_tts_queue
        print("Initializing Llama model...")
        self.llm = Llama(
            model_path=config.MODEL_PATH,
            n_gpu_layers=config.N_GPU_LAYERS,
            n_ctx=config.N_CTX,
            verbose=True # è®¾ä¸ºTrueæ–¹ä¾¿è°ƒè¯•
        )
        print("Llama model initialized successfully on GPU.")
        self.conversation_history = [{"role": "system", "content": config.SYSTEM_PROMPT}]

    async def process_llm_responses(self):
        while True:
            text_input = await self.from_asr_queue.get()
            print(f"LLM received: {text_input}")
            
            self.conversation_history.append({"role": "user", "content": text_input})
            
            ai_response_chunks = []
            
            # ä½¿ç”¨æµå¼ç”Ÿæˆ
            stream = self.llm.create_chat_completion(
                messages=self.conversation_history,
                stream=True,
            )
            
            for chunk in stream:
                delta = chunk['choices'][0]['delta']
                if 'content' in delta and delta['content']:
                    token = delta['content']
                    ai_response_chunks.append(token)
                    await self.to_tts_queue.put(token) # å…³é”®ï¼šç«‹å³å°†tokené€å»TTS
            
            # å°†å®Œæ•´çš„AIå›å¤å­˜å…¥å†å²è®°å½•
            full_response = "".join(ai_response_chunks)
            self.conversation_history.append({"role": "assistant", "content": full_response})
            print(f"LLM generated: {full_response}")
```

---

### `asr_handler.py` & `tts_handler.py` (æ¦‚å¿µæ€§ä»£ç )

> **ç»™Cursorçš„æç¤º**: è¯·ä½¿ç”¨ `deepgram-sdk` å’Œ `elevenlabs` åº“çš„å¼‚æ­¥å’Œæµå¼åŠŸèƒ½æ¥å®ç°ä»¥ä¸‹é€»è¾‘ã€‚

#### `asr_handler.py` é€»è¾‘:
- ä½¿ç”¨ `asyncio` å’Œ `websockets` è¿æ¥åˆ°Deepgramçš„æµå¼APIã€‚
- ä½¿ç”¨ `sounddevice.InputStream` æ•è·éº¦å…‹é£éŸ³é¢‘ã€‚
- å°†éŸ³é¢‘å—å®æ—¶å‘é€åˆ°Deepgramã€‚
- ç›‘å¬ `LiveTranscriptionEvents.TRANSCRIPT_RECEIVED` äº‹ä»¶ã€‚
- å½“æ”¶åˆ°ä¸€ä¸ª`is_final=True`çš„è½¬å½•ç‰‡æ®µæ—¶ï¼Œå°†å…¶æ”¾å…¥ `to_llm_queue`ã€‚
- **æ‰“æ–­é€»è¾‘**: åœ¨æ­¤æ¨¡å—ä¸­å®ç°ä¸€ä¸ªçŠ¶æ€æœºã€‚å¦‚æœTTSæ­£åœ¨æ’­æ”¾æ—¶ï¼ˆ`is_speaking`çŠ¶æ€ä¸ºTrueï¼‰ï¼Œæ”¶åˆ°äº†æ–°çš„ç”¨æˆ·è¯­éŸ³è½¬å½•ï¼Œç«‹å³å‘å‡ºä¸€ä¸ªâ€œæ‰“æ–­â€ä¿¡å·ï¼ˆä¾‹å¦‚ï¼Œé€šè¿‡ä¸€ä¸ª`asyncio.Event`ï¼‰ã€‚

#### `tts_handler.py` é€»è¾‘:
- åˆ›å»ºä¸€ä¸ªå¼‚æ­¥ç”Ÿæˆå™¨å‡½æ•°ï¼Œå®ƒä¼šä¸æ–­ä» `from_llm_queue` ä¸­ `await queue.get()` æ¥è·å–æ–‡æœ¬tokenã€‚
- ä½¿ç”¨ `elevenlabs` åº“çš„ `stream` åŠŸèƒ½ï¼Œå¹¶å°†ä¸Šè¿°ç”Ÿæˆå™¨ä½œä¸ºè¾“å…¥ã€‚
- `elevenlabs.stream` å‡½æ•°ä¼šè¿”å›ä¸€ä¸ªéŸ³é¢‘æµï¼Œç›´æ¥ä½¿ç”¨`elevenlabs.play()`æ¥æ’­æ”¾å®ƒã€‚
- **æ‰“æ–­é€»è¾‘**: ç›‘å¬â€œæ‰“æ–­â€ä¿¡å·ã€‚å¦‚æœæ”¶åˆ°ä¿¡å·ï¼Œéœ€è¦ç«‹å³åœæ­¢éŸ³é¢‘æ’­æ”¾ã€‚è¿™å¯èƒ½éœ€è¦ä¸­æ–­ `elevenlabs.play()` æˆ–ç®¡ç†åº•å±‚çš„æ’­æ”¾æµã€‚

---

### `main.py` (è°ƒåº¦ä¸­å¿ƒ)
```python
import asyncio
import queue
from llm_handler import LLMHandler
# å¯¼å…¥ä½ å°†è¦åˆ›å»ºçš„ ASR å’Œ TTS å¤„ç†å™¨
# from asr_handler import ASRHandler 
# from tts_handler import TTSHandler

async def main():
    # ä½¿ç”¨asyncioçš„é˜Ÿåˆ—ï¼Œå› ä¸ºå®ƒä»¬æ˜¯ä¸ºåç¨‹è®¾è®¡çš„
    asr_to_llm_queue = asyncio.Queue()
    llm_to_tts_queue = asyncio.Queue()
    
    # æ‰“æ–­äº‹ä»¶
    interruption_event = asyncio.Event()

    # åˆå§‹åŒ–å„ä¸ªæ¨¡å—
    # asr_handler = ASRHandler(asr_to_llm_queue, interruption_event)
    llm_handler = LLMHandler(asr_to_llm_queue, llm_to_tts_queue)
    # tts_handler = TTSHandler(llm_to_tts_queue, interruption_event)

    print("Starting all handlers...")

    # åˆ›å»ºå¹¶è¿è¡Œæ‰€æœ‰ä»»åŠ¡
    # è¿™æ˜¯æ¦‚å¿µæ€§çš„ï¼Œä½ éœ€è¦å¡«å…… ASR å’Œ TTS çš„å…·ä½“å®ç°
    asr_task = asyncio.create_task(asr_handler.start_transcribing())
    llm_task = asyncio.create_task(llm_handler.process_llm_responses())
    tts_task = asyncio.create_task(tts_handler.start_speaking())
    
    try:
        await asyncio.gather(asr_task, llm_task, tts_task)
    except asyncio.CancelledError:
        print("Main task cancelled.")
    finally:
        print("Shutting down handlers...")
        # åœ¨è¿™é‡Œæ·»åŠ æ¸…ç†é€»è¾‘ï¼Œä¾‹å¦‚å…³é—­è¿æ¥

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nProgram interrupted by user. Exiting.")

```

## 6. Phase 3: è¿è¡Œä¸è°ƒè¯•

1.  ç¡®ä¿ä½ çš„è™šæ‹Ÿç¯å¢ƒå·²æ¿€æ´» (`source venv/bin/activate`)ã€‚
2.  ç¡®ä¿ `.env` æ–‡ä»¶å’Œæ¨¡å‹æ–‡ä»¶è·¯å¾„æ­£ç¡®ã€‚
3.  è¿è¡Œä¸»ç¨‹åº: `python main.py`ã€‚
4.  è§‚å¯Ÿç»ˆç«¯è¾“å‡ºã€‚`llama.cpp`çš„æ—¥å¿—ä¼šå‘Šè¯‰ä½ GPUæ˜¯å¦è¢«æˆåŠŸåˆ©ç”¨ã€‚
5.  å¼€å§‹å¯¹ç€éº¦å…‹é£è¯´è¯ï¼Œäº«å—ä½ çš„æé€ŸAIåŠ©æ‰‹ï¼

## 7. ä¸‹ä¸€æ­¥ä¸æ”¹è¿›

*   **å®Œå–„æ‰“æ–­é€»è¾‘**: å®ç°ä¸€ä¸ªæ›´é²æ£’çš„çŠ¶æ€ç®¡ç†å™¨æ¥å¤„ç†æ‰“æ–­ï¼Œç¡®ä¿ä»»åŠ¡èƒ½è¢«å¹²å‡€åœ°å–æ¶ˆå’Œé‡å¯ã€‚
*   **å£°éŸ³å…‹éš†**: ä½¿ç”¨ElevenLabsçš„å£°éŸ³å…‹éš†åŠŸèƒ½ï¼Œè®©AIç”¨ä½ è‡ªå·±çš„å£°éŸ³å›ç­”ã€‚
*   **æ·»åŠ â€œæ€è€ƒâ€éŸ³æ•ˆ**: åœ¨ASRè¯†åˆ«å®Œæˆåˆ°TTSå¼€å§‹æ’­æ”¾ä¹‹é—´ï¼Œæ’­æ”¾ä¸€ä¸ªçŸ­æš‚çš„ã€éé˜»å¡çš„éŸ³æ•ˆï¼Œæå‡äº¤äº’ä½“éªŒã€‚
*   **ä¸Šä¸‹æ–‡ç®¡ç†**: å®ç°æ›´å¤æ‚çš„å¯¹è¯å†å²ç®¡ç†ç­–ç•¥ï¼Œä¾‹å¦‚æ»‘åŠ¨çª—å£æˆ–æ‘˜è¦ï¼Œä»¥æ›´å¥½åœ°åˆ©ç”¨æœ‰é™çš„`n_ctx`ã€‚
